{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- new data from remm se output\n",
    "- old data from wfrc data portal\n",
    "- before running I standarized the column names\n",
    "\n",
    "Create a Feature Layer for each combination of Map Display Geography (4) x Variables (7) wherein the attribute fields are \n",
    "\n",
    "  Like this for Households (for the other 6 variables substitute hh_ with: pop_, ijb_, ojb, rjb_, tjb_,  hji_)\n",
    "\n",
    "TAZID, city, county, med_dist, small_dist, dev_acres, hh_19, hh_20, hh_21…hh_50…old_hh_20, old_hh_25, old_hh_50\n",
    "Sml_DistID, county, dev_acres, hh_19, hh_20, hh_21…hh_50…old_hh_20, old_hh_25, old_hh_50\n",
    "Med_DistID, county, dev_acres, hh_19, hh_20, hh_21…hh_50…old_hh_20, old_hh_25, old_hh_50\n",
    "CityID, county, dev_acres, hh_19, hh_20, hh_21…hh_50…old_hh_20, old_hh_25, old_hh_50\n",
    "\n",
    "\n",
    "### For the map:\n",
    "<!-- 1. obtain taz 832 and 900 shapefile -->\n",
    "<!-- 2. attributes we need:\n",
    "  - total households\n",
    "  - total population\n",
    "  - total jobs\n",
    "  - industrial jobs(5,10) \n",
    "  - retail jobs(1,9) \n",
    "  - office jobs(6,4,3)\n",
    "  - typical jobs (sum of three types, calculated)\n",
    "  - HJ Intensity (this is (HH * 1.8) + Jobs) -->\n",
    "<!-- 3. get taz outout from 2019 REMM -->\n",
    "<!-- 4. get Official TAZ output from 2015 REMM (confirm TAZ version) -->\n",
    "<!-- 5. Generate folder structure -->\n",
    "6. Apportion new taz data to:\n",
    "  - taz 9.0.0\n",
    "  - medium district\n",
    "  - city\n",
    "  - small district (later)\n",
    "7. Apportion old taz data to:\n",
    "  - taz 9.0.0\n",
    "  - medium district\n",
    "  - city\n",
    "  - small district (later)\n",
    "8. create shapefiles/feature classes for each attribute (see #2)\n",
    "\n",
    "### For the chart:\n",
    "1. create a json for each record using the following geographies:\n",
    "  - taz\n",
    "  - medium district\n",
    "  - city\n",
    "  - small district (later)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import glob\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "import pandas as pd\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)\n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# parcels = r'.\\\\Inputs\\\\remm_base_year_20220513.gdb\\\\parcels_2019'\n",
    "taz832 = r\".\\Inputs\\TAZ_832_ID_Only.shp\"\n",
    "taz900 = r\".\\Inputs\\TAZ_900.shp\"\n",
    "cities = r\".\\Inputs\\CityArea.shp\"\n",
    "# small_districts = ???\n",
    "# regions_df = pd.DataFrame.spatial.from_featureclass(regions_shp)\n",
    "\n",
    "taz832_sdf = pd.DataFrame.spatial.from_featureclass(taz832)\n",
    "taz900_sdf = pd.DataFrame.spatial.from_featureclass(taz900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_folder = r\".\\New_SE_Data\"\n",
    "new_taz_se = glob.glob(os.path.join(pm_folder,'SE_WF_*.csv'))\n",
    "len(new_taz_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_se_folder = r\".\\Old_SE_Data\"\n",
    "old_taz_se = glob.glob(os.path.join(old_se_folder,'*_TAZ.csv'))\n",
    "old_city_se = glob.glob(os.path.join(old_se_folder,'*_City_Area.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = r'.\\Outputs'\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "\n",
    "scratch = os.path.join(outputs, 'scratch.gdb')\n",
    "if not arcpy.Exists(scratch):\n",
    "    arcpy.CreateFileGDB_management(outputs, 'scratch.gdb')\n",
    "\n",
    "map_folder = os.path.join(outputs, \"map\")\n",
    "if not os.path.exists(map_folder):\n",
    "    os.makedirs(map_folder)\n",
    "\n",
    "chart_folder = os.path.join(outputs, \"chart\")\n",
    "if not os.path.exists(chart_folder):\n",
    "    os.makedirs(chart_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = os.path.splitext(os.path.basename(new_taz_se[0]))[0].split('_')[-1]\n",
    "# x = pd.read_csv(new_taz_se[0])\n",
    "# x['OFFI'] = x['OFFI'] + x['GVED'] + x['HLTH']\n",
    "# x['TPCL'] = x['OFFI'] + x['RETEMP'] + x['INDEMP']\n",
    "# x['HJI'] = x['TOTHH']*1.8 + x['TOTEMP']\n",
    "# x = x[[';TAZID', 'TOTHH', 'HHPOP', 'TOTEMP','RETEMP', 'INDEMP', 'OFFI', 'TPCL', 'HJI']].copy()\n",
    "# x.columns = ['TAZID', f'HH_{year}', f'POP_{year}', f'EMP_{year}', f'RTL_{year}', f'IND_{year}', f'OFFI_{year}', f'TPCL_{year}', f'HJI_{year}']\n",
    "# x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process New SE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = taz832_sdf[['TAZID','SHAPE']].copy()\n",
    "base.shape\n",
    "\n",
    "for csv in new_taz_se:\n",
    "\n",
    "    year = os.path.splitext(os.path.basename(csv))[0].split('_')[-1]\n",
    "    df = pd.read_csv(csv)\n",
    "    df['OFFI'] = df['OFFI'] + df['GVED'] + df['HLTH']\n",
    "    df['TPCL'] = df['OFFI'] + df['RETEMP'] + df['INDEMP']\n",
    "    df['HJI'] = df['TOTHH']*1.8 + df['TOTEMP']\n",
    "    df = df[[';TAZID', 'TOTHH', 'HHPOP', 'TOTEMP','RETEMP', 'INDEMP', 'OFFI', 'TPCL', 'HJI']].copy()\n",
    "    df.columns = ['TAZID', f'HH_{year}', f'POP_{year}', f'EMP_{year}', f'RTL_{year}', f'IND_{year}', f'OFFI_{year}', f'TPCL_{year}', f'HJI_{year}']\n",
    "    \n",
    "    base = base.merge(df, on='TAZID', how='left')\n",
    "\n",
    "new_se = base\n",
    "new_se.rename({'TAZID': 'TAZID832'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 258)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Process-Progression-Metrics-For-Web\\\\Outputs\\\\scratch.gdb\\\\_01_new_se_taz_832'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "new_se_taz_832 = os.path.join(scratch, '_01_new_se_taz_832')\n",
    "new_se.spatial.to_featureclass(location=new_se_taz_832,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Old SE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_dict =  {'TOTHH':'HH',    \n",
    "            'HHPOP':'POP',\n",
    "            'RETEMP':'RTL',\n",
    "            'TOTEMP':'TPCL',\n",
    "            'ALLEMP':'EMP',\n",
    "            'INDEMP':'IND',\n",
    "            'OTHEMP':'OFFI'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv(old_taz_se[0])\n",
    "# category = se_dict[test.iloc[0]['SECategory']]\n",
    "# val_cols = [col for col in list(test.columns) if 'YEAR' in col and  'D' not in col and int(col[4:]) >= 2019]\n",
    "# test = test[['CO_TAZID'] + val_cols]\n",
    "# new_val_cols = [col.replace('YEAR',category + '_') for col in val_cols]\n",
    "# test.columns = ['CO_TAZID'] + new_val_cols\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_base = taz832_sdf[['CO_TAZID','SHAPE']].copy()\n",
    "old_base.shape\n",
    "\n",
    "for csv in old_taz_se:\n",
    "\n",
    "    df = pd.read_csv(csv)\n",
    "    category = se_dict[df.iloc[0]['SECategory']]\n",
    "    val_cols = [col for col in list(df.columns) if 'YEAR' in col and  'D' not in col and int(col[4:]) >= 2019]\n",
    "    df = df[['CO_TAZID'] + val_cols]\n",
    "    new_val_cols = [col.replace('YEAR',category + '_') for col in val_cols]\n",
    "    df.columns = ['CO_TAZID'] + new_val_cols\n",
    "    old_base = old_base.merge(df, on='CO_TAZID',how='left')\n",
    "\n",
    "old_se = old_base\n",
    "old_se.rename({'CO_TAZID': 'COTAZID832'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate household jobs index\n",
    "for year in range(2019,2051):\n",
    "    old_se['HJI_{}'.format(year)] = (old_se['HH_{}'.format(year)] * 1.8) + old_se['EMP_{}'.format(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 258)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Process-Progression-Metrics-For-Web\\\\Outputs\\\\scratch.gdb\\\\_02_old_se_taz_832'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "old_se_taz_832 = os.path.join(scratch, '_02_old_se_taz_832')\n",
    "old_se.spatial.to_featureclass(location=old_se_taz_832,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare output dimensions\n",
    "old_se.shape == new_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, June 9, 2022 5:45:22 PM\",\"Succeeded at Thursday, June 9, 2022 5:45:56 PM (Elapsed Time: 33.69 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\scratch.gdb\\\\_03_taz832_cities_identity'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge geometry between taz 832 and output geometries (taz900, )\n",
    "taz900_identity = arcpy.Identity_analysis(taz900, new_se_taz_832, os.path.join(scratch, '_03_taz832_taz900_identity'))\n",
    "arcpy.management.DeleteField(taz900_identity,['TAZID', 'DISTMED'], \"KEEP_FIELDS\")\n",
    "\n",
    "cities_identity = arcpy.Identity_analysis(cities, new_se_taz_832,os.path.join(scratch, '_03_taz832_cities_identity'))\n",
    "arcpy.management.DeleteField(cities_identity,'CityArea', \"KEEP_FIELDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apportion the attributes from old geometry to the new ones\n",
    "\n",
    "- The Apportion tool in arcpy is still lame \n",
    "- we have to run a command (apportion_command_for_arcgis_pro.txt) in the arcgis pro python window to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apportion = arcpy.ApportionPolygon_analysis(new_se_taz_832, app_columns, identity, os.path.join(outputs, 'new_se_apportion_to_taz900.shp'), \"AREA\", \"\", \"\", \"MAINTAIN_GEOMETRIES\")\n",
    "new_taz_apportion = os.path.join(scratch,'_05_new_se_apportion_to_taz900')\n",
    "new_city_apportion = os.path.join(scratch,'_05_new_se_apportion_to_cities')\n",
    "old_taz_apportion = os.path.join(scratch,'_05_old_se_apportion_to_taz900')\n",
    "old_city_apportion = os.path.join(scratch,'_05_old_se_apportion_to_cities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissolve to get to desired geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_columns = list(new_se.columns)[2:]\n",
    "stat_fields = [[col,'SUM'] for col in app_columns]\n",
    "\n",
    "#########\n",
    "# New\n",
    "#########\n",
    "\n",
    "# taz (9.0.0)\n",
    "new_se_taz900_dissolve = arcpy.Dissolve_management(new_taz_apportion, os.path.join(scratch, '_06_new_se_taz900_dissolve'),\n",
    "                          'TAZID', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# distmed (9.0.0)\n",
    "new_se_distmed_dissolve = arcpy.Dissolve_management(new_taz_apportion, os.path.join(scratch, '_06_new_se_distmed_dissolve'),\n",
    "                          'DISTMED', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# city area\n",
    "new_se_cityarea_dissolve = arcpy.Dissolve_management(new_city_apportion, os.path.join(scratch, '_06_new_se_cityarea_dissolve'),\n",
    "                          'CITYAREA', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Old\n",
    "#########\n",
    "\n",
    "# taz (9.0.0)\n",
    "old_se_taz900_dissolve = arcpy.Dissolve_management(old_taz_apportion, os.path.join(scratch, '_06_old_se_taz900_dissolve'),\n",
    "                          'TAZID', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# distmed (9.0.0)\n",
    "old_se_distmed_dissolve = arcpy.Dissolve_management(old_taz_apportion, os.path.join(scratch, '_06_old_se_distmed_dissolve'),\n",
    "                          'DISTMED', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# city area\n",
    "old_se_cityarea_dissolve = arcpy.Dissolve_management(old_city_apportion, os.path.join(scratch, '_06_old_se_cityarea_dissolve'),\n",
    "                          'CITYAREA', stat_fields, \"MULTI_PART\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_se_taz900_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_taz900_dissolve[0])\n",
    "new_se_distmed_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_distmed_dissolve[0])\n",
    "new_se_cityarea_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_cityarea_dissolve[0])\n",
    "old_se_taz900_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_taz900_dissolve[0])\n",
    "old_se_distmed_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_distmed_dissolve[0])\n",
    "old_se_cityarea_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_cityarea_dissolve[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SUM_HH_2019': 'HH_2019',\n",
       " 'SUM_POP_2019': 'POP_2019',\n",
       " 'SUM_EMP_2019': 'EMP_2019',\n",
       " 'SUM_RTL_2019': 'RTL_2019',\n",
       " 'SUM_IND_2019': 'IND_2019',\n",
       " 'SUM_OFFI_2019': 'OFFI_2019',\n",
       " 'SUM_TPCL_2019': 'TPCL_2019',\n",
       " 'SUM_HJI_2019': 'HJI_2019',\n",
       " 'SUM_HH_2020': 'HH_2020',\n",
       " 'SUM_POP_2020': 'POP_2020',\n",
       " 'SUM_EMP_2020': 'EMP_2020',\n",
       " 'SUM_RTL_2020': 'RTL_2020',\n",
       " 'SUM_IND_2020': 'IND_2020',\n",
       " 'SUM_OFFI_2020': 'OFFI_2020',\n",
       " 'SUM_TPCL_2020': 'TPCL_2020',\n",
       " 'SUM_HJI_2020': 'HJI_2020',\n",
       " 'SUM_HH_2021': 'HH_2021',\n",
       " 'SUM_POP_2021': 'POP_2021',\n",
       " 'SUM_EMP_2021': 'EMP_2021',\n",
       " 'SUM_RTL_2021': 'RTL_2021',\n",
       " 'SUM_IND_2021': 'IND_2021',\n",
       " 'SUM_OFFI_2021': 'OFFI_2021',\n",
       " 'SUM_TPCL_2021': 'TPCL_2021',\n",
       " 'SUM_HJI_2021': 'HJI_2021',\n",
       " 'SUM_HH_2022': 'HH_2022',\n",
       " 'SUM_POP_2022': 'POP_2022',\n",
       " 'SUM_EMP_2022': 'EMP_2022',\n",
       " 'SUM_RTL_2022': 'RTL_2022',\n",
       " 'SUM_IND_2022': 'IND_2022',\n",
       " 'SUM_OFFI_2022': 'OFFI_2022',\n",
       " 'SUM_TPCL_2022': 'TPCL_2022',\n",
       " 'SUM_HJI_2022': 'HJI_2022',\n",
       " 'SUM_HH_2023': 'HH_2023',\n",
       " 'SUM_POP_2023': 'POP_2023',\n",
       " 'SUM_EMP_2023': 'EMP_2023',\n",
       " 'SUM_RTL_2023': 'RTL_2023',\n",
       " 'SUM_IND_2023': 'IND_2023',\n",
       " 'SUM_OFFI_2023': 'OFFI_2023',\n",
       " 'SUM_TPCL_2023': 'TPCL_2023',\n",
       " 'SUM_HJI_2023': 'HJI_2023',\n",
       " 'SUM_HH_2024': 'HH_2024',\n",
       " 'SUM_POP_2024': 'POP_2024',\n",
       " 'SUM_EMP_2024': 'EMP_2024',\n",
       " 'SUM_RTL_2024': 'RTL_2024',\n",
       " 'SUM_IND_2024': 'IND_2024',\n",
       " 'SUM_OFFI_2024': 'OFFI_2024',\n",
       " 'SUM_TPCL_2024': 'TPCL_2024',\n",
       " 'SUM_HJI_2024': 'HJI_2024',\n",
       " 'SUM_HH_2025': 'HH_2025',\n",
       " 'SUM_POP_2025': 'POP_2025',\n",
       " 'SUM_EMP_2025': 'EMP_2025',\n",
       " 'SUM_RTL_2025': 'RTL_2025',\n",
       " 'SUM_IND_2025': 'IND_2025',\n",
       " 'SUM_OFFI_2025': 'OFFI_2025',\n",
       " 'SUM_TPCL_2025': 'TPCL_2025',\n",
       " 'SUM_HJI_2025': 'HJI_2025',\n",
       " 'SUM_HH_2026': 'HH_2026',\n",
       " 'SUM_POP_2026': 'POP_2026',\n",
       " 'SUM_EMP_2026': 'EMP_2026',\n",
       " 'SUM_RTL_2026': 'RTL_2026',\n",
       " 'SUM_IND_2026': 'IND_2026',\n",
       " 'SUM_OFFI_2026': 'OFFI_2026',\n",
       " 'SUM_TPCL_2026': 'TPCL_2026',\n",
       " 'SUM_HJI_2026': 'HJI_2026',\n",
       " 'SUM_HH_2027': 'HH_2027',\n",
       " 'SUM_POP_2027': 'POP_2027',\n",
       " 'SUM_EMP_2027': 'EMP_2027',\n",
       " 'SUM_RTL_2027': 'RTL_2027',\n",
       " 'SUM_IND_2027': 'IND_2027',\n",
       " 'SUM_OFFI_2027': 'OFFI_2027',\n",
       " 'SUM_TPCL_2027': 'TPCL_2027',\n",
       " 'SUM_HJI_2027': 'HJI_2027',\n",
       " 'SUM_HH_2028': 'HH_2028',\n",
       " 'SUM_POP_2028': 'POP_2028',\n",
       " 'SUM_EMP_2028': 'EMP_2028',\n",
       " 'SUM_RTL_2028': 'RTL_2028',\n",
       " 'SUM_IND_2028': 'IND_2028',\n",
       " 'SUM_OFFI_2028': 'OFFI_2028',\n",
       " 'SUM_TPCL_2028': 'TPCL_2028',\n",
       " 'SUM_HJI_2028': 'HJI_2028',\n",
       " 'SUM_HH_2029': 'HH_2029',\n",
       " 'SUM_POP_2029': 'POP_2029',\n",
       " 'SUM_EMP_2029': 'EMP_2029',\n",
       " 'SUM_RTL_2029': 'RTL_2029',\n",
       " 'SUM_IND_2029': 'IND_2029',\n",
       " 'SUM_OFFI_2029': 'OFFI_2029',\n",
       " 'SUM_TPCL_2029': 'TPCL_2029',\n",
       " 'SUM_HJI_2029': 'HJI_2029',\n",
       " 'SUM_HH_2030': 'HH_2030',\n",
       " 'SUM_POP_2030': 'POP_2030',\n",
       " 'SUM_EMP_2030': 'EMP_2030',\n",
       " 'SUM_RTL_2030': 'RTL_2030',\n",
       " 'SUM_IND_2030': 'IND_2030',\n",
       " 'SUM_OFFI_2030': 'OFFI_2030',\n",
       " 'SUM_TPCL_2030': 'TPCL_2030',\n",
       " 'SUM_HJI_2030': 'HJI_2030',\n",
       " 'SUM_HH_2031': 'HH_2031',\n",
       " 'SUM_POP_2031': 'POP_2031',\n",
       " 'SUM_EMP_2031': 'EMP_2031',\n",
       " 'SUM_RTL_2031': 'RTL_2031',\n",
       " 'SUM_IND_2031': 'IND_2031',\n",
       " 'SUM_OFFI_2031': 'OFFI_2031',\n",
       " 'SUM_TPCL_2031': 'TPCL_2031',\n",
       " 'SUM_HJI_2031': 'HJI_2031',\n",
       " 'SUM_HH_2032': 'HH_2032',\n",
       " 'SUM_POP_2032': 'POP_2032',\n",
       " 'SUM_EMP_2032': 'EMP_2032',\n",
       " 'SUM_RTL_2032': 'RTL_2032',\n",
       " 'SUM_IND_2032': 'IND_2032',\n",
       " 'SUM_OFFI_2032': 'OFFI_2032',\n",
       " 'SUM_TPCL_2032': 'TPCL_2032',\n",
       " 'SUM_HJI_2032': 'HJI_2032',\n",
       " 'SUM_HH_2033': 'HH_2033',\n",
       " 'SUM_POP_2033': 'POP_2033',\n",
       " 'SUM_EMP_2033': 'EMP_2033',\n",
       " 'SUM_RTL_2033': 'RTL_2033',\n",
       " 'SUM_IND_2033': 'IND_2033',\n",
       " 'SUM_OFFI_2033': 'OFFI_2033',\n",
       " 'SUM_TPCL_2033': 'TPCL_2033',\n",
       " 'SUM_HJI_2033': 'HJI_2033',\n",
       " 'SUM_HH_2034': 'HH_2034',\n",
       " 'SUM_POP_2034': 'POP_2034',\n",
       " 'SUM_EMP_2034': 'EMP_2034',\n",
       " 'SUM_RTL_2034': 'RTL_2034',\n",
       " 'SUM_IND_2034': 'IND_2034',\n",
       " 'SUM_OFFI_2034': 'OFFI_2034',\n",
       " 'SUM_TPCL_2034': 'TPCL_2034',\n",
       " 'SUM_HJI_2034': 'HJI_2034',\n",
       " 'SUM_HH_2035': 'HH_2035',\n",
       " 'SUM_POP_2035': 'POP_2035',\n",
       " 'SUM_EMP_2035': 'EMP_2035',\n",
       " 'SUM_RTL_2035': 'RTL_2035',\n",
       " 'SUM_IND_2035': 'IND_2035',\n",
       " 'SUM_OFFI_2035': 'OFFI_2035',\n",
       " 'SUM_TPCL_2035': 'TPCL_2035',\n",
       " 'SUM_HJI_2035': 'HJI_2035',\n",
       " 'SUM_HH_2036': 'HH_2036',\n",
       " 'SUM_POP_2036': 'POP_2036',\n",
       " 'SUM_EMP_2036': 'EMP_2036',\n",
       " 'SUM_RTL_2036': 'RTL_2036',\n",
       " 'SUM_IND_2036': 'IND_2036',\n",
       " 'SUM_OFFI_2036': 'OFFI_2036',\n",
       " 'SUM_TPCL_2036': 'TPCL_2036',\n",
       " 'SUM_HJI_2036': 'HJI_2036',\n",
       " 'SUM_HH_2037': 'HH_2037',\n",
       " 'SUM_POP_2037': 'POP_2037',\n",
       " 'SUM_EMP_2037': 'EMP_2037',\n",
       " 'SUM_RTL_2037': 'RTL_2037',\n",
       " 'SUM_IND_2037': 'IND_2037',\n",
       " 'SUM_OFFI_2037': 'OFFI_2037',\n",
       " 'SUM_TPCL_2037': 'TPCL_2037',\n",
       " 'SUM_HJI_2037': 'HJI_2037',\n",
       " 'SUM_HH_2038': 'HH_2038',\n",
       " 'SUM_POP_2038': 'POP_2038',\n",
       " 'SUM_EMP_2038': 'EMP_2038',\n",
       " 'SUM_RTL_2038': 'RTL_2038',\n",
       " 'SUM_IND_2038': 'IND_2038',\n",
       " 'SUM_OFFI_2038': 'OFFI_2038',\n",
       " 'SUM_TPCL_2038': 'TPCL_2038',\n",
       " 'SUM_HJI_2038': 'HJI_2038',\n",
       " 'SUM_HH_2039': 'HH_2039',\n",
       " 'SUM_POP_2039': 'POP_2039',\n",
       " 'SUM_EMP_2039': 'EMP_2039',\n",
       " 'SUM_RTL_2039': 'RTL_2039',\n",
       " 'SUM_IND_2039': 'IND_2039',\n",
       " 'SUM_OFFI_2039': 'OFFI_2039',\n",
       " 'SUM_TPCL_2039': 'TPCL_2039',\n",
       " 'SUM_HJI_2039': 'HJI_2039',\n",
       " 'SUM_HH_2040': 'HH_2040',\n",
       " 'SUM_POP_2040': 'POP_2040',\n",
       " 'SUM_EMP_2040': 'EMP_2040',\n",
       " 'SUM_RTL_2040': 'RTL_2040',\n",
       " 'SUM_IND_2040': 'IND_2040',\n",
       " 'SUM_OFFI_2040': 'OFFI_2040',\n",
       " 'SUM_TPCL_2040': 'TPCL_2040',\n",
       " 'SUM_HJI_2040': 'HJI_2040',\n",
       " 'SUM_HH_2041': 'HH_2041',\n",
       " 'SUM_POP_2041': 'POP_2041',\n",
       " 'SUM_EMP_2041': 'EMP_2041',\n",
       " 'SUM_RTL_2041': 'RTL_2041',\n",
       " 'SUM_IND_2041': 'IND_2041',\n",
       " 'SUM_OFFI_2041': 'OFFI_2041',\n",
       " 'SUM_TPCL_2041': 'TPCL_2041',\n",
       " 'SUM_HJI_2041': 'HJI_2041',\n",
       " 'SUM_HH_2042': 'HH_2042',\n",
       " 'SUM_POP_2042': 'POP_2042',\n",
       " 'SUM_EMP_2042': 'EMP_2042',\n",
       " 'SUM_RTL_2042': 'RTL_2042',\n",
       " 'SUM_IND_2042': 'IND_2042',\n",
       " 'SUM_OFFI_2042': 'OFFI_2042',\n",
       " 'SUM_TPCL_2042': 'TPCL_2042',\n",
       " 'SUM_HJI_2042': 'HJI_2042',\n",
       " 'SUM_HH_2043': 'HH_2043',\n",
       " 'SUM_POP_2043': 'POP_2043',\n",
       " 'SUM_EMP_2043': 'EMP_2043',\n",
       " 'SUM_RTL_2043': 'RTL_2043',\n",
       " 'SUM_IND_2043': 'IND_2043',\n",
       " 'SUM_OFFI_2043': 'OFFI_2043',\n",
       " 'SUM_TPCL_2043': 'TPCL_2043',\n",
       " 'SUM_HJI_2043': 'HJI_2043',\n",
       " 'SUM_HH_2044': 'HH_2044',\n",
       " 'SUM_POP_2044': 'POP_2044',\n",
       " 'SUM_EMP_2044': 'EMP_2044',\n",
       " 'SUM_RTL_2044': 'RTL_2044',\n",
       " 'SUM_IND_2044': 'IND_2044',\n",
       " 'SUM_OFFI_2044': 'OFFI_2044',\n",
       " 'SUM_TPCL_2044': 'TPCL_2044',\n",
       " 'SUM_HJI_2044': 'HJI_2044',\n",
       " 'SUM_HH_2045': 'HH_2045',\n",
       " 'SUM_POP_2045': 'POP_2045',\n",
       " 'SUM_EMP_2045': 'EMP_2045',\n",
       " 'SUM_RTL_2045': 'RTL_2045',\n",
       " 'SUM_IND_2045': 'IND_2045',\n",
       " 'SUM_OFFI_2045': 'OFFI_2045',\n",
       " 'SUM_TPCL_2045': 'TPCL_2045',\n",
       " 'SUM_HJI_2045': 'HJI_2045',\n",
       " 'SUM_HH_2046': 'HH_2046',\n",
       " 'SUM_POP_2046': 'POP_2046',\n",
       " 'SUM_EMP_2046': 'EMP_2046',\n",
       " 'SUM_RTL_2046': 'RTL_2046',\n",
       " 'SUM_IND_2046': 'IND_2046',\n",
       " 'SUM_OFFI_2046': 'OFFI_2046',\n",
       " 'SUM_TPCL_2046': 'TPCL_2046',\n",
       " 'SUM_HJI_2046': 'HJI_2046',\n",
       " 'SUM_HH_2047': 'HH_2047',\n",
       " 'SUM_POP_2047': 'POP_2047',\n",
       " 'SUM_EMP_2047': 'EMP_2047',\n",
       " 'SUM_RTL_2047': 'RTL_2047',\n",
       " 'SUM_IND_2047': 'IND_2047',\n",
       " 'SUM_OFFI_2047': 'OFFI_2047',\n",
       " 'SUM_TPCL_2047': 'TPCL_2047',\n",
       " 'SUM_HJI_2047': 'HJI_2047',\n",
       " 'SUM_HH_2048': 'HH_2048',\n",
       " 'SUM_POP_2048': 'POP_2048',\n",
       " 'SUM_EMP_2048': 'EMP_2048',\n",
       " 'SUM_RTL_2048': 'RTL_2048',\n",
       " 'SUM_IND_2048': 'IND_2048',\n",
       " 'SUM_OFFI_2048': 'OFFI_2048',\n",
       " 'SUM_TPCL_2048': 'TPCL_2048',\n",
       " 'SUM_HJI_2048': 'HJI_2048',\n",
       " 'SUM_HH_2049': 'HH_2049',\n",
       " 'SUM_POP_2049': 'POP_2049',\n",
       " 'SUM_EMP_2049': 'EMP_2049',\n",
       " 'SUM_RTL_2049': 'RTL_2049',\n",
       " 'SUM_IND_2049': 'IND_2049',\n",
       " 'SUM_OFFI_2049': 'OFFI_2049',\n",
       " 'SUM_TPCL_2049': 'TPCL_2049',\n",
       " 'SUM_HJI_2049': 'HJI_2049',\n",
       " 'SUM_HH_2050': 'HH_2050',\n",
       " 'SUM_POP_2050': 'POP_2050',\n",
       " 'SUM_EMP_2050': 'EMP_2050',\n",
       " 'SUM_RTL_2050': 'RTL_2050',\n",
       " 'SUM_IND_2050': 'IND_2050',\n",
       " 'SUM_OFFI_2050': 'OFFI_2050',\n",
       " 'SUM_TPCL_2050': 'TPCL_2050',\n",
       " 'SUM_HJI_2050': 'HJI_2050'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_columns\n",
    "to_replace = ['SUM_'+ col for col in app_columns]\n",
    "replace_dict = dict(zip(to_replace, app_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store each df in list\n",
    "# get name/geography\n",
    "# pair old and new tables\n",
    "# rename old columns\n",
    "# create separate dataframe for each category, remove category from field names\n",
    "# export each category to separate shapefile to map folder\n",
    "# process to json to chart folder"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3245673af07dcc28bdd829afb187282e9288a1f8195a5928b70ecba6e5973721"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
