{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- new data from remm se output\n",
    "- old data from wfrc data portal\n",
    "- before running I standarized the column names\n",
    "- Filter city areas\n",
    "\n",
    "Create a Feature Layer for each combination of Map Display Geography (4) x Variables (7) wherein the attribute fields are \n",
    "\n",
    "  Like this for Households (for the other 6 variables substitute hh_ with: pop_, ijb_, ojb, rjb_, tjb_,  hji_)\n",
    "\n",
    "TAZID, city, county, med_dist, small_dist, dev_acres, hh_19, hh_20, hh_21…hh_50…old_hh_20, old_hh_25, old_hh_50\n",
    "Sml_DistID, county, dev_acres, hh_19, hh_20, hh_21…hh_50…old_hh_20, old_hh_25, old_hh_50\n",
    "Med_DistID, county, dev_acres, hh_19, hh_20, hh_21…hh_50…old_hh_20, old_hh_25, old_hh_50\n",
    "CityID, county, dev_acres, hh_19, hh_20, hh_21…hh_50…old_hh_20, old_hh_25, old_hh_50\n",
    "\n",
    "\n",
    "### For the map:\n",
    "<!-- 1. obtain taz 832 and 900 shapefile -->\n",
    "<!-- 2. attributes we need:\n",
    "  - total households\n",
    "  - total population\n",
    "  - total jobs\n",
    "  - industrial jobs(5,10) \n",
    "  - retail jobs(1,9) \n",
    "  - office jobs(6,4,3)\n",
    "  - typical jobs (sum of three types, calculated)\n",
    "  - HJ Intensity (this is (HH * 1.8) + Jobs) -->\n",
    "<!-- 3. get taz outout from 2019 REMM -->\n",
    "<!-- 4. get Official TAZ output from 2015 REMM (confirm TAZ version) -->\n",
    "<!-- 5. Generate folder structure -->\n",
    "6. Apportion new taz data to:\n",
    "  - taz 9.0.0\n",
    "  - medium district\n",
    "  - city\n",
    "  - small district (later)\n",
    "7. Apportion old taz data to:\n",
    "  - taz 9.0.0\n",
    "  - medium district\n",
    "  - city\n",
    "  - small district (later)\n",
    "8. create shapefiles/feature classes for each attribute (see #2)\n",
    "\n",
    "### For the chart:\n",
    "1. create a json for each record using the following geographies:\n",
    "  - taz\n",
    "  - medium district\n",
    "  - city\n",
    "  - small district (later)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import glob\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "import pandas as pd\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)\n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# parcels = r'.\\\\Inputs\\\\remm_base_year_20220513.gdb\\\\parcels_2019'\n",
    "taz832 = r\".\\Inputs\\TAZ_832_ID_Only.shp\"\n",
    "taz900 = r\".\\Inputs\\TAZ_900.shp\"\n",
    "cities = r\".\\Inputs\\CityArea_UTM12.shp\"\n",
    "# small_districts = ???\n",
    "# regions_df = pd.DataFrame.spatial.from_featureclass(regions_shp)\n",
    "\n",
    "taz832_sdf = pd.DataFrame.spatial.from_featureclass(taz832)\n",
    "taz900_sdf = pd.DataFrame.spatial.from_featureclass(taz900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_folder = r\".\\New_SE_Data\"\n",
    "new_taz_se = glob.glob(os.path.join(pm_folder,'SE_WF_*.csv'))\n",
    "len(new_taz_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_se_folder = r\".\\Old_SE_Data\"\n",
    "old_taz_se = glob.glob(os.path.join(old_se_folder,'*_TAZ.csv'))\n",
    "old_city_se = glob.glob(os.path.join(old_se_folder,'*_City_Area.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = r'.\\Outputs'\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "\n",
    "scratch = os.path.join(outputs, 'scratch.gdb')\n",
    "if not arcpy.Exists(scratch):\n",
    "    arcpy.CreateFileGDB_management(outputs, 'scratch.gdb')\n",
    "\n",
    "map_folder = os.path.join(outputs, \"map\")\n",
    "if not os.path.exists(map_folder):\n",
    "    os.makedirs(map_folder)\n",
    "\n",
    "chart_folder = os.path.join(outputs, \"chart\")\n",
    "if not os.path.exists(chart_folder):\n",
    "    os.makedirs(chart_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = os.path.splitext(os.path.basename(new_taz_se[0]))[0].split('_')[-1]\n",
    "# x = pd.read_csv(new_taz_se[0])\n",
    "# x['OFFI'] = x['OFFI'] + x['GVED'] + x['HLTH']\n",
    "# x['TPCL'] = x['OFFI'] + x['RETEMP'] + x['INDEMP']\n",
    "# x['HJI'] = x['TOTHH']*1.8 + x['TOTEMP']\n",
    "# x = x[[';TAZID', 'TOTHH', 'HHPOP', 'TOTEMP','RETEMP', 'INDEMP', 'OFFI', 'TPCL', 'HJI']].copy()\n",
    "# x.columns = ['TAZID', f'HH_{year}', f'POP_{year}', f'EMP_{year}', f'RTL_{year}', f'IND_{year}', f'OFFI_{year}', f'TPCL_{year}', f'HJI_{year}']\n",
    "# x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process New SE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = taz832_sdf[['TAZID','SHAPE']].copy()\n",
    "base.shape\n",
    "\n",
    "for csv in new_taz_se:\n",
    "\n",
    "    year = os.path.splitext(os.path.basename(csv))[0].split('_')[-1]\n",
    "    df = pd.read_csv(csv)\n",
    "    df['OFFI'] = df['OFFI'] + df['GVED'] + df['HLTH']\n",
    "    df['TPCL'] = df['OFFI'] + df['RETEMP'] + df['INDEMP']\n",
    "    df['HJI'] = df['TOTHH']*1.8 + df['TOTEMP']\n",
    "    df = df[[';TAZID', 'TOTHH', 'HHPOP', 'TOTEMP','RETEMP', 'INDEMP', 'OFFI', 'TPCL', 'HJI']].copy()\n",
    "    df.columns = ['TAZID', f'HH_{year}', f'POP_{year}', f'EMP_{year}', f'RTL_{year}', f'IND_{year}', f'OFFI_{year}', f'TPCL_{year}', f'HJI_{year}']\n",
    "    \n",
    "    base = base.merge(df, on='TAZID', how='left')\n",
    "\n",
    "new_se = base\n",
    "new_se.rename({'TAZID': 'TAZID832'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 258)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Process-Progression-Metrics-For-Web\\\\Outputs\\\\scratch.gdb\\\\_01_new_se_taz_832'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "new_se_taz_832 = os.path.join(scratch, '_01_new_se_taz_832')\n",
    "new_se.spatial.to_featureclass(location=new_se_taz_832,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Old SE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_dict =  {'TOTHH':'HH',    \n",
    "            'HHPOP':'POP',\n",
    "            'RETEMP':'RTL',\n",
    "            'TOTEMP':'TPCL',\n",
    "            'ALLEMP':'EMP',\n",
    "            'INDEMP':'IND',\n",
    "            'OTHEMP':'OFFI'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv(old_taz_se[0])\n",
    "# category = se_dict[test.iloc[0]['SECategory']]\n",
    "# val_cols = [col for col in list(test.columns) if 'YEAR' in col and  'D' not in col and int(col[4:]) >= 2019]\n",
    "# test = test[['CO_TAZID'] + val_cols]\n",
    "# new_val_cols = [col.replace('YEAR',category + '_') for col in val_cols]\n",
    "# test.columns = ['CO_TAZID'] + new_val_cols\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_base = taz832_sdf[['CO_TAZID','SHAPE']].copy()\n",
    "old_base.shape\n",
    "\n",
    "for csv in old_taz_se:\n",
    "\n",
    "    df = pd.read_csv(csv)\n",
    "    category = se_dict[df.iloc[0]['SECategory']]\n",
    "    val_cols = [col for col in list(df.columns) if 'YEAR' in col and  'D' not in col and int(col[4:]) >= 2019]\n",
    "    df = df[['CO_TAZID'] + val_cols]\n",
    "    new_val_cols = [col.replace('YEAR',category + '_') for col in val_cols]\n",
    "    df.columns = ['CO_TAZID'] + new_val_cols\n",
    "    old_base = old_base.merge(df, on='CO_TAZID',how='left')\n",
    "\n",
    "old_se = old_base\n",
    "old_se.rename({'CO_TAZID': 'COTAZID832'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate household jobs index\n",
    "for year in range(2019,2051):\n",
    "    old_se['HJI_{}'.format(year)] = (old_se['HH_{}'.format(year)] * 1.8) + old_se['EMP_{}'.format(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 258)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Process-Progression-Metrics-For-Web\\\\Outputs\\\\scratch.gdb\\\\_02_old_se_taz_832'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "old_se_taz_832 = os.path.join(scratch, '_02_old_se_taz_832')\n",
    "old_se.spatial.to_featureclass(location=old_se_taz_832,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare output dimensions\n",
    "old_se.shape == new_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, June 10, 2022 9:15:30 AM\",\"Succeeded at Friday, June 10, 2022 9:16:03 AM (Elapsed Time: 33.61 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\scratch.gdb\\\\_03_taz832_cities_identity'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge geometry between taz 832 and output geometries (taz900, )\n",
    "taz900_identity = arcpy.Identity_analysis(taz900, new_se_taz_832, os.path.join(scratch, '_03_taz832_taz900_identity'))\n",
    "arcpy.management.DeleteField(taz900_identity,['TAZID', 'DISTMED'], \"KEEP_FIELDS\")\n",
    "\n",
    "cities_identity = arcpy.Identity_analysis(cities, new_se_taz_832,os.path.join(scratch, '_03_taz832_cities_identity'))\n",
    "arcpy.management.DeleteField(cities_identity,'CityArea', \"KEEP_FIELDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apportion the attributes from old geometry to the new ones\n",
    "\n",
    "- The Apportion tool in arcpy is still lame \n",
    "- we have to run a command (apportion_command_for_arcgis_pro.txt) in the arcgis pro python window to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.startfile(r\".\\REMM-Process-Progression-Metrics-For-Web.aprx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apportion = arcpy.ApportionPolygon_analysis(new_se_taz_832, app_columns, identity, os.path.join(outputs, 'new_se_apportion_to_taz900.shp'), \"AREA\", \"\", \"\", \"MAINTAIN_GEOMETRIES\")\n",
    "new_taz_apportion = os.path.join(scratch,'_05_new_se_apportion_to_taz900')\n",
    "new_city_apportion = os.path.join(scratch,'_05_new_se_apportion_to_cities')\n",
    "old_taz_apportion = os.path.join(scratch,'_05_old_se_apportion_to_taz900')\n",
    "old_city_apportion = os.path.join(scratch,'_05_old_se_apportion_to_cities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissolve to get to desired geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_columns = list(new_se.columns)[2:]\n",
    "stat_fields = [[col,'SUM'] for col in app_columns]\n",
    "\n",
    "#########\n",
    "# New\n",
    "#########\n",
    "\n",
    "# taz (9.0.0)\n",
    "new_se_taz900_dissolve = arcpy.Dissolve_management(new_taz_apportion, os.path.join(scratch, '_06_new_se_taz900_dissolve'),\n",
    "                          'TAZID', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# distmed (9.0.0)\n",
    "new_se_distmed_dissolve = arcpy.Dissolve_management(new_taz_apportion, os.path.join(scratch, '_06_new_se_distmed_dissolve'),\n",
    "                          'DISTMED', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# city area\n",
    "new_se_cityarea_dissolve = arcpy.Dissolve_management(new_city_apportion, os.path.join(scratch, '_06_new_se_cityarea_dissolve'),\n",
    "                          'CITYAREA', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Old\n",
    "#########\n",
    "\n",
    "# taz (9.0.0)\n",
    "old_se_taz900_dissolve = arcpy.Dissolve_management(old_taz_apportion, os.path.join(scratch, '_06_old_se_taz900_dissolve'),\n",
    "                          'TAZID', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# distmed (9.0.0)\n",
    "old_se_distmed_dissolve = arcpy.Dissolve_management(old_taz_apportion, os.path.join(scratch, '_06_old_se_distmed_dissolve'),\n",
    "                          'DISTMED', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# city area\n",
    "old_se_cityarea_dissolve = arcpy.Dissolve_management(old_city_apportion, os.path.join(scratch, '_06_old_se_cityarea_dissolve'),\n",
    "                          'CityArea', stat_fields, \"MULTI_PART\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in new dataframes\n",
    "new_se_taz900_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_taz900_dissolve[0])\n",
    "new_se_distmed_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_distmed_dissolve[0])\n",
    "new_se_cityarea_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_cityarea_dissolve[0])\n",
    "old_se_taz900_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_taz900_dissolve[0])\n",
    "old_se_distmed_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_distmed_dissolve[0])\n",
    "old_se_cityarea_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_cityarea_dissolve[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'SUM' from column names\n",
    "to_replace = ['SUM_'+ col for col in app_columns]\n",
    "replace_dict = dict(zip(to_replace, app_columns))\n",
    "\n",
    "new_se_taz900_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "old_se_taz900_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "\n",
    "new_se_distmed_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "old_se_distmed_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "\n",
    "new_se_cityarea_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "old_se_cityarea_dissolve_df.rename(replace_dict, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================\n",
    "# Process TAZ\n",
    "#====================\n",
    "\n",
    "taz_folder = os.path.join(map_folder, \"TAZ\")\n",
    "if not os.path.exists(taz_folder):\n",
    "    os.makedirs(taz_folder)\n",
    "\n",
    "categories = ['HH', 'POP', 'EMP', 'RTL', 'IND', 'OFFI', 'TPCL', 'HJI']\n",
    "for c in categories:\n",
    "    new_cols = [col for col in app_columns if col.split('_')[0] == c]\n",
    "    new_temp_df = new_se_taz900_dissolve_df[['TAZID','SHAPE'] + new_cols].copy()\n",
    "    old_temp_df = old_se_taz900_dissolve_df[['TAZID','SHAPE'] + new_cols].copy()\n",
    "    \n",
    "\n",
    "    new_new_names = [col.replace(c, 'N') for col in new_cols]\n",
    "    new_old_names = [col.replace(c, 'O') for col in new_cols]\n",
    "    new_rename_dict = dict(zip(new_cols, new_new_names))\n",
    "    old_rename_dict = dict(zip(new_cols, new_old_names))\n",
    "    new_temp_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "    old_temp_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "    merged = new_temp_df.merge(old_temp_df, on=['TAZID','SHAPE'], how='left')\n",
    "\n",
    "    merged[new_new_names + new_old_names] = merged[new_new_names + new_old_names].fillna(value=0)\n",
    "\n",
    "    outfile = os.path.join(taz_folder, '{}_PROJECTIONS_by_TAZ.shp'.format(c))\n",
    "    merged.spatial.to_featureclass(location=outfile, sanitize_columns=False)\n",
    "\n",
    "    arcpy.AddField_management(outfile, \"ACRES\", \"FLOAT\")\n",
    "    exp = \"round(!SHAPE.AREA@ACRES!,2)\"\n",
    "    arcpy.CalculateField_management(outfile, \"ACRES\", exp, \"PYTHON3\")\n",
    "\n",
    "    # convert to json\n",
    "    category_folder = os.path.join(chart_folder, 'TAZ', c)\n",
    "    if not os.path.exists(category_folder):\n",
    "        os.makedirs(category_folder)\n",
    "\n",
    "    for index, row in merged.iterrows():\n",
    "        f = open(os.path.join(category_folder, \"TAZ_{}.json\".format(row['TAZID'])), \"a\")\n",
    "        cols = [col for col in  merged.columns if col.split('_')[0]=='N']\n",
    "    \n",
    "        f.write(\"[\\n\")\n",
    "\n",
    "        for col in cols:\n",
    "            f.write(\"\\t{\\n\")\n",
    "            f.write('''\\t\\t\"C\":\"{}\",\\n'''.format(c))\n",
    "            f.write('''\\t\\t\"Y\":{},\\n'''.format(col.split('_')[1]))\n",
    "            f.write('''\\t\\t\"V\":{}\\n'''.format(row[col]))\n",
    "            \n",
    "            if col.split('_')[1] != \"2050\":\n",
    "                f.write(\"\\t},\\n\")\n",
    "            else:\n",
    "                f.write(\"\\t}\\n\")\n",
    "\n",
    "        f.write(\"]\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================\n",
    "# Process DISTMED\n",
    "#====================\n",
    "\n",
    "distmed_folder = os.path.join(map_folder, \"DISTMED\")\n",
    "if not os.path.exists(distmed_folder):\n",
    "    os.makedirs(distmed_folder)\n",
    "\n",
    "categories = ['HH', 'POP', 'EMP', 'RTL', 'IND', 'OFFI', 'TPCL', 'HJI']\n",
    "for c in categories:\n",
    "    new_cols = [col for col in app_columns if col.split('_')[0] == c]\n",
    "    new_temp_df = new_se_distmed_dissolve_df[['DISTMED','SHAPE'] + new_cols].copy()\n",
    "    old_temp_df = old_se_distmed_dissolve_df[['DISTMED','SHAPE'] + new_cols].copy()\n",
    "    \n",
    "\n",
    "    new_new_names = [col.replace(c, 'N') for col in new_cols]\n",
    "    new_old_names = [col.replace(c, 'O') for col in new_cols]\n",
    "    new_rename_dict = dict(zip(new_cols, new_new_names))\n",
    "    old_rename_dict = dict(zip(new_cols, new_old_names))\n",
    "    new_temp_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "    old_temp_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "    merged = new_temp_df.merge(old_temp_df, on=['DISTMED','SHAPE'], how='left')\n",
    "\n",
    "    merged[new_new_names + new_old_names] = merged[new_new_names + new_old_names].fillna(value=0)\n",
    "    merged[new_new_names + new_old_names] = merged[new_new_names + new_old_names].round(0)\n",
    "\n",
    "    outfile = os.path.join(distmed_folder, '{}_PROJECTIONS_by_DISTMED.shp'.format(c))\n",
    "    merged.spatial.to_featureclass(location=outfile, sanitize_columns=False)\n",
    "\n",
    "    arcpy.AddField_management(outfile, \"ACRES\", \"FLOAT\")\n",
    "    exp = \"round(!SHAPE.AREA@ACRES!,2)\"\n",
    "    arcpy.CalculateField_management(outfile, \"ACRES\", exp, \"PYTHON3\")\n",
    "\n",
    "    # convert to json\n",
    "    category_folder = os.path.join(chart_folder, 'DISTMED', c)\n",
    "    if not os.path.exists(category_folder):\n",
    "        os.makedirs(category_folder)\n",
    "\n",
    "    for index, row in merged.iterrows():\n",
    "        f = open(os.path.join(category_folder, \"DISTMED_{}.json\".format(row['DISTMED'])), \"a\")\n",
    "        cols = [col for col in  merged.columns if col.split('_')[0]=='N']\n",
    "    \n",
    "        f.write(\"[\\n\")\n",
    "\n",
    "        for col in cols:\n",
    "            f.write(\"\\t{\\n\")\n",
    "            f.write('''\\t\\t\"C\":\"{}\",\\n'''.format(c))\n",
    "            f.write('''\\t\\t\"Y\":{},\\n'''.format(col.split('_')[1]))\n",
    "            f.write('''\\t\\t\"V\":{}\\n'''.format(row[col]))\n",
    "            \n",
    "            if col.split('_')[1] != \"2050\":\n",
    "                f.write(\"\\t},\\n\")\n",
    "            else:\n",
    "                f.write(\"\\t}\\n\")\n",
    "\n",
    "        f.write(\"]\\n\")\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================\n",
    "# Process City Area\n",
    "#====================\n",
    "\n",
    "cityarea_folder = os.path.join(map_folder, \"CITYAREA\")\n",
    "if not os.path.exists(cityarea_folder):\n",
    "    os.makedirs(cityarea_folder)\n",
    "\n",
    "categories = ['HH', 'POP', 'EMP', 'RTL', 'IND', 'OFFI', 'TPCL', 'HJI']\n",
    "for c in categories:\n",
    "    new_cols = [col for col in app_columns if col.split('_')[0] == c]\n",
    "    new_temp_df = new_se_cityarea_dissolve_df[['CityArea','SHAPE'] + new_cols].copy()\n",
    "    old_temp_df = old_se_cityarea_dissolve_df[['CityArea','SHAPE'] + new_cols].copy()\n",
    "    \n",
    "\n",
    "    new_new_names = [col.replace(c, 'N') for col in new_cols]\n",
    "    new_old_names = [col.replace(c, 'O') for col in new_cols]\n",
    "    new_rename_dict = dict(zip(new_cols, new_new_names))\n",
    "    old_rename_dict = dict(zip(new_cols, new_old_names))\n",
    "    new_temp_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "    old_temp_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "    merged = new_temp_df.merge(old_temp_df, on=['CityArea','SHAPE'], how='left')\n",
    "\n",
    "    merged[new_new_names + new_old_names] = merged[new_new_names + new_old_names].fillna(value=0)\n",
    "\n",
    "\n",
    "    outfile = os.path.join(distmed_folder, '{}_PROJECTIONS_by_CITYAREA.shp'.format(c))\n",
    "    merged.spatial.to_featureclass(location=outfile, sanitize_columns=False)\n",
    "\n",
    "    arcpy.AddField_management(outfile, \"ACRES\", \"FLOAT\")\n",
    "    exp = \"round(!SHAPE.AREA@ACRES!,2)\"\n",
    "    arcpy.CalculateField_management(outfile, \"ACRES\", exp, \"PYTHON3\")\n",
    "\n",
    "    # convert to json\n",
    "    category_folder = os.path.join(chart_folder, 'CITYAREA', c)\n",
    "    if not os.path.exists(category_folder):\n",
    "        os.makedirs(category_folder)\n",
    "\n",
    "    for index, row in merged.iterrows():\n",
    "        f = open(os.path.join(category_folder, \"CITYAREA_{}.json\".format(row['CityArea'])), \"a\")\n",
    "        cols = [col for col in  merged.columns if col.split('_')[0]=='N']\n",
    "    \n",
    "        f.write(\"[\\n\")\n",
    "\n",
    "        for col in cols:\n",
    "            f.write(\"\\t{\\n\")\n",
    "            f.write('''\\t\\t\"C\":\"{}\",\\n'''.format(c))\n",
    "            f.write('''\\t\\t\"Y\":{},\\n'''.format(col.split('_')[1]))\n",
    "            f.write('''\\t\\t\"V\":{}\\n'''.format(row[col]))\n",
    "            \n",
    "            if col.split('_')[1] != \"2050\":\n",
    "                f.write(\"\\t},\\n\")\n",
    "            else:\n",
    "                f.write(\"\\t}\\n\")\n",
    "\n",
    "        f.write(\"]\\n\")\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_folder = os.path.join(chart_folder, c)\n",
    "# if not os.path.exists(category_folder):\n",
    "#     os.makedirs(category_folder)\n",
    "\n",
    "# m = merged.copy()\n",
    "# del m['SHAPE']\n",
    "# m.to_json('file.json', orient='records', lines=True)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CityArea</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>N_2019</th>\n",
       "      <th>N_2020</th>\n",
       "      <th>N_2021</th>\n",
       "      <th>N_2022</th>\n",
       "      <th>N_2023</th>\n",
       "      <th>N_2024</th>\n",
       "      <th>N_2025</th>\n",
       "      <th>N_2026</th>\n",
       "      <th>N_2027</th>\n",
       "      <th>N_2028</th>\n",
       "      <th>N_2029</th>\n",
       "      <th>N_2030</th>\n",
       "      <th>N_2031</th>\n",
       "      <th>N_2032</th>\n",
       "      <th>N_2033</th>\n",
       "      <th>N_2034</th>\n",
       "      <th>N_2035</th>\n",
       "      <th>N_2036</th>\n",
       "      <th>N_2037</th>\n",
       "      <th>N_2038</th>\n",
       "      <th>N_2039</th>\n",
       "      <th>N_2040</th>\n",
       "      <th>N_2041</th>\n",
       "      <th>N_2042</th>\n",
       "      <th>N_2043</th>\n",
       "      <th>N_2044</th>\n",
       "      <th>N_2045</th>\n",
       "      <th>N_2046</th>\n",
       "      <th>N_2047</th>\n",
       "      <th>N_2048</th>\n",
       "      <th>N_2049</th>\n",
       "      <th>N_2050</th>\n",
       "      <th>the_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alpine</td>\n",
       "      <td>{\"rings\": [[[-12442943.7757, 4937264.529899999...</td>\n",
       "      <td>6435.200004</td>\n",
       "      <td>6538.200003</td>\n",
       "      <td>6946.400004</td>\n",
       "      <td>7218.600005</td>\n",
       "      <td>7477.200006</td>\n",
       "      <td>7625.000006</td>\n",
       "      <td>7723.200006</td>\n",
       "      <td>7832.000006</td>\n",
       "      <td>7910.200006</td>\n",
       "      <td>7958.400006</td>\n",
       "      <td>8034.000006</td>\n",
       "      <td>8130.800006</td>\n",
       "      <td>8212.800006</td>\n",
       "      <td>8277.800006</td>\n",
       "      <td>8339.000006</td>\n",
       "      <td>8409.400006</td>\n",
       "      <td>8492.400006</td>\n",
       "      <td>8568.200006</td>\n",
       "      <td>8661.000006</td>\n",
       "      <td>8767.400006</td>\n",
       "      <td>8854.600006</td>\n",
       "      <td>8945.600006</td>\n",
       "      <td>9052.600006</td>\n",
       "      <td>9190.400006</td>\n",
       "      <td>9299.400006</td>\n",
       "      <td>9423.200005</td>\n",
       "      <td>9531.600005</td>\n",
       "      <td>9615.400005</td>\n",
       "      <td>9697.600005</td>\n",
       "      <td>9784.000005</td>\n",
       "      <td>9850.600005</td>\n",
       "      <td>9891.200005</td>\n",
       "      <td>30776463.794043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alta</td>\n",
       "      <td>{\"rings\": [[[-12426519.0222, 4953174.323600002...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144892726.603075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Altamont</td>\n",
       "      <td>{\"rings\": [[[-12276835.5724, 4919352.339000002...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13468399.267567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alton</td>\n",
       "      <td>{\"rings\": [[[-12520939.344700001, 4500318.2993...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9828588.953654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amalga</td>\n",
       "      <td>{\"rings\": [[[-12457630.286, 5144333.3347999975...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26460753.572179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Willard</td>\n",
       "      <td>{\"rings\": [[[-12472854.2697, 5078290.666500002...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21839566.625954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Woodland Hills</td>\n",
       "      <td>{\"rings\": [[[-12429225.6549, 4869928.106600001...</td>\n",
       "      <td>739.799999</td>\n",
       "      <td>772.199999</td>\n",
       "      <td>791.999999</td>\n",
       "      <td>813.599999</td>\n",
       "      <td>829.799999</td>\n",
       "      <td>844.199999</td>\n",
       "      <td>853.199999</td>\n",
       "      <td>865.799999</td>\n",
       "      <td>878.399999</td>\n",
       "      <td>885.599999</td>\n",
       "      <td>901.799999</td>\n",
       "      <td>914.399999</td>\n",
       "      <td>921.599999</td>\n",
       "      <td>923.399999</td>\n",
       "      <td>932.399999</td>\n",
       "      <td>943.199999</td>\n",
       "      <td>957.599999</td>\n",
       "      <td>971.999999</td>\n",
       "      <td>998.999999</td>\n",
       "      <td>1022.399998</td>\n",
       "      <td>1047.599998</td>\n",
       "      <td>1074.599998</td>\n",
       "      <td>1108.799998</td>\n",
       "      <td>1168.199998</td>\n",
       "      <td>1231.199998</td>\n",
       "      <td>1324.799998</td>\n",
       "      <td>1427.399998</td>\n",
       "      <td>1515.599997</td>\n",
       "      <td>1609.199997</td>\n",
       "      <td>1686.599997</td>\n",
       "      <td>1726.199997</td>\n",
       "      <td>1776.599997</td>\n",
       "      <td>11314045.360356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Woodruff</td>\n",
       "      <td>{\"rings\": [[[-12374594.4946, 5090375.112000003...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2125805.706251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Woods Cross</td>\n",
       "      <td>{\"rings\": [[[-12459834.5079, 4995266.601899996...</td>\n",
       "      <td>14516.199956</td>\n",
       "      <td>14212.999959</td>\n",
       "      <td>14843.799954</td>\n",
       "      <td>15077.799953</td>\n",
       "      <td>15157.199953</td>\n",
       "      <td>15520.399948</td>\n",
       "      <td>16105.599941</td>\n",
       "      <td>16424.399938</td>\n",
       "      <td>16705.799935</td>\n",
       "      <td>16977.599932</td>\n",
       "      <td>17291.399930</td>\n",
       "      <td>17547.999929</td>\n",
       "      <td>17700.999928</td>\n",
       "      <td>17811.599927</td>\n",
       "      <td>17913.799927</td>\n",
       "      <td>18078.199926</td>\n",
       "      <td>18183.399925</td>\n",
       "      <td>18249.199925</td>\n",
       "      <td>18353.599924</td>\n",
       "      <td>18488.399924</td>\n",
       "      <td>18697.399923</td>\n",
       "      <td>18865.599922</td>\n",
       "      <td>18998.999922</td>\n",
       "      <td>19118.999921</td>\n",
       "      <td>19391.199921</td>\n",
       "      <td>19582.599921</td>\n",
       "      <td>19735.199921</td>\n",
       "      <td>19882.999920</td>\n",
       "      <td>20172.599920</td>\n",
       "      <td>20234.199921</td>\n",
       "      <td>20686.799921</td>\n",
       "      <td>21157.199919</td>\n",
       "      <td>18266783.84168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Zion National Park</td>\n",
       "      <td>{\"rings\": [[[-12570484.1765, 4449313.633400001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>809366328.688413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CityArea                                              SHAPE  \\\n",
       "0                Alpine  {\"rings\": [[[-12442943.7757, 4937264.529899999...   \n",
       "1                  Alta  {\"rings\": [[[-12426519.0222, 4953174.323600002...   \n",
       "2              Altamont  {\"rings\": [[[-12276835.5724, 4919352.339000002...   \n",
       "3                 Alton  {\"rings\": [[[-12520939.344700001, 4500318.2993...   \n",
       "4                Amalga  {\"rings\": [[[-12457630.286, 5144333.3347999975...   \n",
       "..                  ...                                                ...   \n",
       "293             Willard  {\"rings\": [[[-12472854.2697, 5078290.666500002...   \n",
       "294      Woodland Hills  {\"rings\": [[[-12429225.6549, 4869928.106600001...   \n",
       "295            Woodruff  {\"rings\": [[[-12374594.4946, 5090375.112000003...   \n",
       "296         Woods Cross  {\"rings\": [[[-12459834.5079, 4995266.601899996...   \n",
       "297  Zion National Park  {\"rings\": [[[-12570484.1765, 4449313.633400001...   \n",
       "\n",
       "           N_2019        N_2020        N_2021        N_2022        N_2023  \\\n",
       "0     6435.200004   6538.200003   6946.400004   7218.600005   7477.200006   \n",
       "1        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "293      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "294    739.799999    772.199999    791.999999    813.599999    829.799999   \n",
       "295           NaN           NaN           NaN           NaN           NaN   \n",
       "296  14516.199956  14212.999959  14843.799954  15077.799953  15157.199953   \n",
       "297           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "           N_2024        N_2025        N_2026        N_2027        N_2028  \\\n",
       "0     7625.000006   7723.200006   7832.000006   7910.200006   7958.400006   \n",
       "1        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "293      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "294    844.199999    853.199999    865.799999    878.399999    885.599999   \n",
       "295           NaN           NaN           NaN           NaN           NaN   \n",
       "296  15520.399948  16105.599941  16424.399938  16705.799935  16977.599932   \n",
       "297           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "           N_2029        N_2030        N_2031        N_2032        N_2033  \\\n",
       "0     8034.000006   8130.800006   8212.800006   8277.800006   8339.000006   \n",
       "1        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "293      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "294    901.799999    914.399999    921.599999    923.399999    932.399999   \n",
       "295           NaN           NaN           NaN           NaN           NaN   \n",
       "296  17291.399930  17547.999929  17700.999928  17811.599927  17913.799927   \n",
       "297           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "           N_2034        N_2035        N_2036        N_2037        N_2038  \\\n",
       "0     8409.400006   8492.400006   8568.200006   8661.000006   8767.400006   \n",
       "1        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "293      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "294    943.199999    957.599999    971.999999    998.999999   1022.399998   \n",
       "295           NaN           NaN           NaN           NaN           NaN   \n",
       "296  18078.199926  18183.399925  18249.199925  18353.599924  18488.399924   \n",
       "297           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "           N_2039        N_2040        N_2041        N_2042        N_2043  \\\n",
       "0     8854.600006   8945.600006   9052.600006   9190.400006   9299.400006   \n",
       "1        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "293      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "294   1047.599998   1074.599998   1108.799998   1168.199998   1231.199998   \n",
       "295           NaN           NaN           NaN           NaN           NaN   \n",
       "296  18697.399923  18865.599922  18998.999922  19118.999921  19391.199921   \n",
       "297           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "           N_2044        N_2045        N_2046        N_2047        N_2048  \\\n",
       "0     9423.200005   9531.600005   9615.400005   9697.600005   9784.000005   \n",
       "1        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "293      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "294   1324.799998   1427.399998   1515.599997   1609.199997   1686.599997   \n",
       "295           NaN           NaN           NaN           NaN           NaN   \n",
       "296  19582.599921  19735.199921  19882.999920  20172.599920  20234.199921   \n",
       "297           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "           N_2049        N_2050          the_area  \n",
       "0     9850.600005   9891.200005   30776463.794043  \n",
       "1        0.000000      0.000000  144892726.603075  \n",
       "2             NaN           NaN   13468399.267567  \n",
       "3             NaN           NaN    9828588.953654  \n",
       "4             NaN           NaN   26460753.572179  \n",
       "..            ...           ...               ...  \n",
       "293      0.000000      0.000000   21839566.625954  \n",
       "294   1726.199997   1776.599997   11314045.360356  \n",
       "295           NaN           NaN    2125805.706251  \n",
       "296  20686.799921  21157.199919    18266783.84168  \n",
       "297           NaN           NaN  809366328.688413  \n",
       "\n",
       "[298 rows x 35 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import arcgis.features\n",
    "# from arcgis.features import GeoSeriesAccessor\n",
    "# gsa = arcgis.features.GeoSeriesAccessor(new_temp_df['SHAPE'])\n",
    "# new_temp_df['the_area'] = gsa.area\n",
    "# new_temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = m.iloc[0]\n",
    "# cols = [col for col in  m.columns if col.split('_')[0]=='N']\n",
    "# f = open(\"CITYAREA_{}.json\".format(a['CityArea']), \"a\")\n",
    "\n",
    "\n",
    "# f.write(\"[\\n\")\n",
    "\n",
    "\n",
    "# for col in cols:\n",
    "#     f.write(\"\\t{\\n\")\n",
    "#     f.write('''\\t\\t\"C\":\"{}\",\\n'''.format(c))\n",
    "#     f.write('''\\t\\t\"Y\":{},\\n'''.format(col.split('_')[1]))\n",
    "#     f.write('''\\t\\t\"V\":{}\\n'''.format(a[col]))\n",
    "    \n",
    "#     if col.split('_')[1] != \"2050\":\n",
    "#         f.write(\"\\t},\\n\")\n",
    "#     else:\n",
    "#         f.write(\"\\t}\\n\")\n",
    "\n",
    "# f.write(\"]\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HJI'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3245673af07dcc28bdd829afb187282e9288a1f8195a5928b70ecba6e5973721"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
